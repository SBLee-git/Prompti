{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chroma DB 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\job311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 공고 처리 중 (1/3): https://www.wanted.co.kr/wd/270338\n",
      "✅ 저장 완료: NLP AI 엔지니어 (4개 문장)\n",
      "\n",
      "🔍 공고 처리 중 (2/3): https://www.wanted.co.kr/wd/263703\n",
      "✅ 저장 완료: AI 사업계획서/제안서 작성 담당자 (2개 문장)\n",
      "\n",
      "🔍 공고 처리 중 (3/3): https://www.wanted.co.kr/wd/268265\n",
      "✅ 저장 완료: AI솔루션 영업직 (4개 문장)\n",
      "\n",
      "🎯 모든 작업이 완료되었습니다. ChromaDB 저장 성공.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def scrape_and_store_chromadb(csv_file_path, chroma_path):\n",
    "    # ChromaDB 초기화\n",
    "    client = chromadb.PersistentClient(path=chroma_path)\n",
    "    collection = client.get_or_create_collection(name=\"wanted_jobs\")\n",
    "\n",
    "    # 임베딩 모델 로딩\n",
    "    embedding_model = SentenceTransformer(\"intfloat/multilingual-e5-large-instruct\")\n",
    "\n",
    "    # Text Splitter 설정\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)\n",
    "\n",
    "    # Selenium 환경 설정\n",
    "    CHROMEDRIVER_PATH = r\"./data/chromedriver.exe\"\n",
    "    service = Service(CHROMEDRIVER_PATH)\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    try:\n",
    "        for idx, row in df.iterrows():\n",
    "            job_url = row[\"URL\"]\n",
    "            print(f\"\\n🔍 공고 처리 중 ({idx+1}/{len(df)}): {job_url}\")\n",
    "\n",
    "            driver.get(job_url)\n",
    "            time.sleep(2)\n",
    "\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "\n",
    "            # 포지션명 수집\n",
    "            try:\n",
    "                position_name = driver.find_element(By.CSS_SELECTOR, \"h1\").text.strip()\n",
    "            except:\n",
    "                position_name = \"N/A\"\n",
    "\n",
    "            # 경력 수집\n",
    "            try:\n",
    "                exp_elements = driver.find_elements(By.CSS_SELECTOR, \"span.JobHeader_JobHeader__Tools__Company__Info__yT4OD\")\n",
    "                experience = exp_elements[1].text.strip() if len(exp_elements) > 1 else \"N/A\"\n",
    "            except:\n",
    "                experience = \"N/A\"\n",
    "\n",
    "            # 상세 정보 버튼 클릭\n",
    "            try:\n",
    "                more_btn = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[span[contains(text(),'상세 정보 더 보기')]]\")))\n",
    "                driver.execute_script(\"arguments[0].click();\", more_btn)\n",
    "                time.sleep(2)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # 섹션 구분하여 크롤링 (필수 섹션만)\n",
    "            job_description_list = []\n",
    "            current_section = None\n",
    "\n",
    "            try:\n",
    "                desc_container = driver.find_element(By.CSS_SELECTOR, \"article.JobDescription_JobDescription__dq8G5\")\n",
    "                elements = desc_container.find_elements(By.XPATH, \".//*\")\n",
    "\n",
    "                for el in elements:\n",
    "                    tag_name = el.tag_name.lower()\n",
    "                    text = el.text.strip()\n",
    "\n",
    "                    if tag_name == \"h2\":\n",
    "                        job_description_list.append(f\"[{text}]\")\n",
    "\n",
    "                    elif tag_name == \"h3\":\n",
    "                        if \"주요업무\" in text:\n",
    "                            current_section = \"MainTask\"\n",
    "                            job_description_list.append(f\"\\n{text}\")\n",
    "                        elif \"자격요건\" in text:\n",
    "                            current_section = \"Qualification\"\n",
    "                            job_description_list.append(f\"\\n{text}\")\n",
    "                        elif \"우대사항\" in text:\n",
    "                            current_section = \"Preferred\"\n",
    "                            job_description_list.append(f\"\\n{text}\")\n",
    "                        else:\n",
    "                            current_section = None  # 불필요 섹션 제외\n",
    "\n",
    "                    elif tag_name == \"span\" and current_section:\n",
    "                        job_description_list.append(text)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\" 크롤링 중 오류 발생: {e}\")\n",
    "                continue\n",
    "\n",
    "            # 분할 및 임베딩 처리\n",
    "            full_text = \"\\n\".join(job_description_list).strip()\n",
    "            if not full_text:\n",
    "                continue\n",
    "\n",
    "            split_chunks = text_splitter.split_text(full_text)\n",
    "            embeddings = embedding_model.encode(split_chunks).tolist()\n",
    "\n",
    "            # ✅ 최종적으로 올바른 DB 저장 방식\n",
    "            for i, chunk in enumerate(split_chunks):\n",
    "                collection.add(\n",
    "                    ids=[f\"{idx}-{i}\"],\n",
    "                    documents=[chunk],  # ✅ 문자열 필수\n",
    "                    embeddings=[embeddings[i]],\n",
    "                    metadatas=[{\n",
    "                        \"PositionName\": position_name,\n",
    "                        \"Experience\": experience\n",
    "                    }]\n",
    "                )\n",
    "\n",
    "            print(f\"✅ 저장 완료: {position_name} ({len(split_chunks)}개 문장)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" 전반적인 오류 발생: {e}\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        print(\"\\n 모든 작업이 완료되었습니다. ChromaDB 저장 성공.\")\n",
    "\n",
    "# 최종 코드 실행\n",
    "input_csv = \"./wanted_merged(1).csv\"\n",
    "chroma_db_path = \"./data/chroma_db\"\n",
    "\n",
    "scrape_and_store_chromadb(input_csv, chroma_db_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 RAG 구직자 맞춤형 추천 결과 🔥\n",
      "구직자님의 프로필을 바탕으로 다음 두 가지 포지션을 추천드립니다.\n",
      "\n",
      "### 1. 포지션명: 데이터 분석가 (Data Analyst)\n",
      "\n",
      "- **요구 경력**: 신입\n",
      "- **주요 업무**:\n",
      "  - 데이터 수집 및 정제\n",
      "  - 데이터 분석 및 시각화\n",
      "  - 비즈니스 인사이트 도출\n",
      "- **자격요건**:\n",
      "  - Python 및 Pandas 사용 경험\n",
      "  - 데이터 분석 및 시각화 도구에 대한 이해\n",
      "  - 기본적인 통계 지식\n",
      "- **우대사항**:\n",
      "  - Git을 통한 버전 관리 경험\n",
      "  - 머신러닝 또는 데이터 마이닝 관련 프로젝트 경험\n",
      "\n",
      "**추천 이유**: 구직자님은 Python과 Pandas를 사용한 경험이 있으며, 데이터 처리 및 분석에 대한 기초적인 이해가 있을 것으로 보입니다. 데이터 분석가는 데이터 기반의 의사결정을 지원하는 역할로, 구직자님의 기술적 배경이 잘 맞아떨어집니다. 또한, 신입 포지션이기 때문에 경력에 대한 부담이 적습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. 포지션명: 머신러닝 엔지니어 (Machine Learning Engineer)\n",
      "\n",
      "- **요구 경력**: 신입\n",
      "- **주요 업무**:\n",
      "  - 머신러닝 모델 개발 및 배포\n",
      "  - 데이터 전처리 및 모델 학습\n",
      "  - 성능 평가 및 최적화\n",
      "- **자격요건**:\n",
      "  - Python 및 PyTorch 사용 경험\n",
      "  - 머신러닝 및 딥러닝 기본 지식\n",
      "  - LLM(대형 언어 모델) 관련 프로젝트 경험\n",
      "- **우대사항**:\n",
      "  - Transformers 라이브러리 사용 경험\n",
      "  - Git을 통한 협업 경험\n",
      "\n",
      "**추천 이유**: 구직자님은 LLM을 이용한 프로젝트 경험이 있으며, PyTorch와 Transformers에 대한 사용 경험도 가지고 있습니다. 머신러닝 엔지니어는 이러한 기술을 활용하여 모델을 개발하고 최적화하는 역할을 수행하므로, 구직자님의 경험이 매우 적합합니다. 또한, 신입 포지션으로 경력에 대한 부담이 적어 도전하기 좋은 기회입니다.\n",
      "\n",
      "이 두 가지 포지션은 구직자님의 기술적 배경과 프로젝트 경험을 잘 활용할 수 있는 기회를 제공할 것입니다.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "\n",
    "# API 키 설정 \n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "# ChromaDB 경로 설정\n",
    "chroma_db_path = \"./data/chroma_db\"\n",
    "\n",
    "# Embedding 모델 설정 (ChromaDB 저장 시 사용한 것과 동일한 모델)\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-large-instruct\"\n",
    ")\n",
    "\n",
    "# ChromaDB에서 벡터DB 로드 (LangChain 인터페이스 사용)\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=chroma_db_path,\n",
    "    embedding_function=embedding_model\n",
    ")\n",
    "\n",
    "# Retriever 설정 (유사한 문서 2개 검색)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\":2})\n",
    "\n",
    "# LLM 인스턴스 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 사용자 프로필 입력 예시 (실제 서비스에서는 사용자 입력을 활용)\n",
    "user_profile = \"\"\"\n",
    "저는 신입입니다. LLM을 이용하여 가사 생성, 일기 생성의 프로젝트 경험이 있고, pandas, git, python, transformers,pytorch 등 사용 경험이 있습니다.\n",
    "나한테 알맞는 직무가 모가 있나요?\n",
    "\"\"\"\n",
    "\n",
    "# Retriever를 통해 문서 검색\n",
    "retrieved_docs = retriever.get_relevant_documents(user_profile)\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "# RAG를 위한 명확한 프롬프트 설정\n",
    "template = \"\"\"\n",
    "당신은 채용 전문가입니다. 주어진 내용을 참고하여 구직자에게 가장 적합한 포지션을 추천하세요.\n",
    "\n",
    "[내용]:\n",
    "{context}\n",
    "\n",
    "[구직자 프로필]:\n",
    "{user_profile}\n",
    "\n",
    "추천 가이드라인:\n",
    "- 구직자에게 가장 잘 맞는 포지션을 최대 2개 추천합니다.\n",
    "- 각 포지션의 포지션명, 요구 경력, 주요 업무, 자격요건, 우대사항을 명확히 제시합니다.\n",
    "- 각 추천에 대해 구직자의 프로필과 어떤 점이 일치하는지 명확히 제시합니다.\n",
    "- 추천의 이유도 제시합니다.\n",
    "                                          \n",
    "\n",
    "추천 결과:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 프롬프트 완성 후 LLM 전달\n",
    "final_prompt = prompt.format_messages(context=context, user_profile=user_profile)\n",
    "\n",
    "# LLM 호출 \n",
    "response = llm.invoke(final_prompt)\n",
    "\n",
    "# 최종 결과 출력\n",
    "print(\" RAG 구직자 맞춤형 추천 결과 \")\n",
    "print(response.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "job311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
