{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê¸°ì¡´ csvë°ì´í„°ì˜ urlë¡œ ë“¤ì–´ê°€ í•„ìš”í•œ ë°ì´í„°ë§Œ í¬ë¡¤ë§\n",
    "- í¬ì§€ì…˜ëª…,ê²½ë ¥,ì£¼ìš”ì—…ë¬´,ìê²©ìš”ê±´,ìš°ëŒ€ì‚¬í•­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” í¬ë¡¤ë§ ì¤‘ (1/3): https://www.wanted.co.kr/wd/270338\n",
      "\n",
      "ğŸ” í¬ë¡¤ë§ ì¤‘ (2/3): https://www.wanted.co.kr/wd/263703\n",
      "\n",
      "ğŸ” í¬ë¡¤ë§ ì¤‘ (3/3): https://www.wanted.co.kr/wd/268265\n",
      "\n",
      "âœ… í¬ë¡¤ë§ ì™„ë£Œ ë° JSON ì €ì¥ ì„±ê³µ\n"
     ]
    }
   ],
   "source": [
    "import json, re\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# ì „ì²˜ë¦¬ í•¨ìˆ˜ \n",
    "def preprocess_text(text: str) -> str:\n",
    "    text = re.sub(r'[â€¢ã†]', ' ', text)\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    lines = text.split('\\n')\n",
    "    unique_lines = []\n",
    "    seen = set()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line and line not in seen:\n",
    "            unique_lines.append(line)\n",
    "            seen.add(line)\n",
    "\n",
    "    cleaned_text = \"\\n\".join(unique_lines).strip()\n",
    "    return cleaned_text\n",
    "\n",
    "def scrape_jobs_to_json(csv_file_path, output_json_path):\n",
    "    CHROMEDRIVER_PATH = r\"./data/chromedriver.exe\"\n",
    "    service = Service(CHROMEDRIVER_PATH)\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    job_list = []\n",
    "\n",
    "    try:\n",
    "        for idx, row in df.iterrows():\n",
    "            job_url = row[\"URL\"]\n",
    "            print(f\"\\nğŸ” í¬ë¡¤ë§ ì¤‘ ({idx+1}/{len(df)}): {job_url}\")\n",
    "\n",
    "            driver.get(job_url)\n",
    "            time.sleep(2)\n",
    "\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "            \n",
    "            # 1) í¬ì§€ì…˜ëª…, ê²½ë ¥\n",
    "            try:\n",
    "                position_name = driver.find_element(By.CSS_SELECTOR, \"h1\").text.strip()\n",
    "            except:\n",
    "                position_name = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                exp_elements = driver.find_elements(By.CSS_SELECTOR, \"span.JobHeader_JobHeader__Tools__Company__Info__yT4OD\")\n",
    "                experience = exp_elements[1].text.strip() if len(exp_elements) > 1 else \"N/A\"\n",
    "            except:\n",
    "                experience = \"N/A\"\n",
    "\n",
    "            # 2) ìƒì„¸ ì •ë³´ ë²„íŠ¼ í´ë¦­\n",
    "            try:\n",
    "                more_btn = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[span[contains(text(),'ìƒì„¸ ì •ë³´ ë” ë³´ê¸°')]]\")))\n",
    "                driver.execute_script(\"arguments[0].click();\", more_btn)\n",
    "                time.sleep(2)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # (3) ì„¹ì…˜ë³„ ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„\n",
    "            main_task_list = []\n",
    "            qualification_list = []\n",
    "            preferred_list = []\n",
    "            current_section = None\n",
    "\n",
    "            # (4) h3/span íƒœê·¸ë§Œ ìˆ˜ì§‘\n",
    "            try:\n",
    "                desc_container = driver.find_element(By.CSS_SELECTOR, \"article.JobDescription_JobDescription__dq8G5\")\n",
    "                elements = desc_container.find_elements(By.XPATH, \".//*\")\n",
    "\n",
    "                for el in elements:\n",
    "                    tag_name = el.tag_name.lower()\n",
    "                    text = el.text.strip()\n",
    "\n",
    "                    # â˜… h2ëŠ” ë¬´ì¡°ê±´ ë¬´ì‹œ\n",
    "                    if tag_name == \"h2\":\n",
    "                        continue  # ìˆ˜ì§‘ ì•ˆ í•¨\n",
    "\n",
    "                    elif tag_name == \"h3\":\n",
    "                        # h3 íƒœê·¸ê°€ \"ì£¼ìš”ì—…ë¬´\", \"ìê²©ìš”ê±´\", \"ìš°ëŒ€ì‚¬í•­\"ì¸ì§€ í™•ì¸\n",
    "                        if \"ì£¼ìš”ì—…ë¬´\" in text:\n",
    "                            current_section = \"MainTask\"\n",
    "                        elif \"ìê²©ìš”ê±´\" in text:\n",
    "                            current_section = \"Qualification\"\n",
    "                        elif \"ìš°ëŒ€ì‚¬í•­\" in text:\n",
    "                            current_section = \"Preferred\"\n",
    "                        else:\n",
    "                            current_section = None\n",
    "\n",
    "                    elif tag_name == \"span\" and current_section:\n",
    "                        # í˜„ì¬ ì„¹ì…˜ì´ ë¬´ì—‡ì¸ì§€ì— ë”°ë¼ ë‹¤ë¥¸ ë¦¬ìŠ¤íŠ¸ì— í…ìŠ¤íŠ¸ ì¶”ê°€\n",
    "                        if current_section == \"MainTask\":\n",
    "                            main_task_list.append(text)\n",
    "                        elif current_section == \"Qualification\":\n",
    "                            qualification_list.append(text)\n",
    "                        elif current_section == \"Preferred\":\n",
    "                            preferred_list.append(text)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "                continue\n",
    "\n",
    "          #  ì „ì²˜ë¦¬ ì ìš©\n",
    "            main_task_clean = preprocess_text(\"\\n\".join(main_task_list))\n",
    "            qualification_clean = preprocess_text(\"\\n\".join(qualification_list))\n",
    "            preferred_clean = preprocess_text(\"\\n\".join(preferred_list))\n",
    "\n",
    "            job_list.append({\n",
    "                \"PositionName\": position_name,\n",
    "                \"Experience\": experience,\n",
    "                \"MainTask\": main_task_clean,\n",
    "                \"Qualification\": qualification_clean,\n",
    "                \"Preferred\": preferred_clean\n",
    "            })\n",
    "\n",
    "        # JSON ì €ì¥\n",
    "        with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(job_list, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        print(\"\\nâœ… í¬ë¡¤ë§ ì™„ë£Œ ë° JSON ì €ì¥ ì„±ê³µ\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# ì‹¤í–‰\n",
    "input_csv = \"./wanted_merged(1).csv\"\n",
    "output_json = \"./jobs.json\"\n",
    "scrape_jobs_to_json(input_csv, output_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "job311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
