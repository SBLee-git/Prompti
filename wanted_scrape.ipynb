{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기존 csv데이터의 url로 들어가 필요한 데이터만 크롤링\n",
    "- 포지션명,경력,주요업무,자격요건,우대사항"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 크롤링 중 (1/3): https://www.wanted.co.kr/wd/270338\n",
      "\n",
      "🔍 크롤링 중 (2/3): https://www.wanted.co.kr/wd/263703\n",
      "\n",
      "🔍 크롤링 중 (3/3): https://www.wanted.co.kr/wd/268265\n",
      "\n",
      "✅ 크롤링 완료 및 JSON 저장 성공\n"
     ]
    }
   ],
   "source": [
    "import json, re\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# 전처리 함수 \n",
    "def preprocess_text(text: str) -> str:\n",
    "    text = re.sub(r'[•ㆍ]', ' ', text)\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    lines = text.split('\\n')\n",
    "    unique_lines = []\n",
    "    seen = set()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line and line not in seen:\n",
    "            unique_lines.append(line)\n",
    "            seen.add(line)\n",
    "\n",
    "    cleaned_text = \"\\n\".join(unique_lines).strip()\n",
    "    return cleaned_text\n",
    "\n",
    "def scrape_jobs_to_json(csv_file_path, output_json_path):\n",
    "    CHROMEDRIVER_PATH = r\"./data/chromedriver.exe\"\n",
    "    service = Service(CHROMEDRIVER_PATH)\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    job_list = []\n",
    "\n",
    "    try:\n",
    "        for idx, row in df.iterrows():\n",
    "            job_url = row[\"URL\"]\n",
    "            print(f\"\\n🔍 크롤링 중 ({idx+1}/{len(df)}): {job_url}\")\n",
    "\n",
    "            driver.get(job_url)\n",
    "            time.sleep(2)\n",
    "\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "            \n",
    "            # 1) 포지션명, 경력\n",
    "            try:\n",
    "                position_name = driver.find_element(By.CSS_SELECTOR, \"h1\").text.strip()\n",
    "            except:\n",
    "                position_name = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                exp_elements = driver.find_elements(By.CSS_SELECTOR, \"span.JobHeader_JobHeader__Tools__Company__Info__yT4OD\")\n",
    "                experience = exp_elements[1].text.strip() if len(exp_elements) > 1 else \"N/A\"\n",
    "            except:\n",
    "                experience = \"N/A\"\n",
    "\n",
    "            # 2) 상세 정보 버튼 클릭\n",
    "            try:\n",
    "                more_btn = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[span[contains(text(),'상세 정보 더 보기')]]\")))\n",
    "                driver.execute_script(\"arguments[0].click();\", more_btn)\n",
    "                time.sleep(2)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # (3) 섹션별 리스트 준비\n",
    "            main_task_list = []\n",
    "            qualification_list = []\n",
    "            preferred_list = []\n",
    "            current_section = None\n",
    "\n",
    "            # (4) h3/span 태그만 수집\n",
    "            try:\n",
    "                desc_container = driver.find_element(By.CSS_SELECTOR, \"article.JobDescription_JobDescription__dq8G5\")\n",
    "                elements = desc_container.find_elements(By.XPATH, \".//*\")\n",
    "\n",
    "                for el in elements:\n",
    "                    tag_name = el.tag_name.lower()\n",
    "                    text = el.text.strip()\n",
    "\n",
    "                    # ★ h2는 무조건 무시\n",
    "                    if tag_name == \"h2\":\n",
    "                        continue  # 수집 안 함\n",
    "\n",
    "                    elif tag_name == \"h3\":\n",
    "                        # h3 태그가 \"주요업무\", \"자격요건\", \"우대사항\"인지 확인\n",
    "                        if \"주요업무\" in text:\n",
    "                            current_section = \"MainTask\"\n",
    "                        elif \"자격요건\" in text:\n",
    "                            current_section = \"Qualification\"\n",
    "                        elif \"우대사항\" in text:\n",
    "                            current_section = \"Preferred\"\n",
    "                        else:\n",
    "                            current_section = None\n",
    "\n",
    "                    elif tag_name == \"span\" and current_section:\n",
    "                        # 현재 섹션이 무엇인지에 따라 다른 리스트에 텍스트 추가\n",
    "                        if current_section == \"MainTask\":\n",
    "                            main_task_list.append(text)\n",
    "                        elif current_section == \"Qualification\":\n",
    "                            qualification_list.append(text)\n",
    "                        elif current_section == \"Preferred\":\n",
    "                            preferred_list.append(text)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"오류 발생: {e}\")\n",
    "                continue\n",
    "\n",
    "          #  전처리 적용\n",
    "            main_task_clean = preprocess_text(\"\\n\".join(main_task_list))\n",
    "            qualification_clean = preprocess_text(\"\\n\".join(qualification_list))\n",
    "            preferred_clean = preprocess_text(\"\\n\".join(preferred_list))\n",
    "\n",
    "            job_list.append({\n",
    "                \"PositionName\": position_name,\n",
    "                \"Experience\": experience,\n",
    "                \"MainTask\": main_task_clean,\n",
    "                \"Qualification\": qualification_clean,\n",
    "                \"Preferred\": preferred_clean\n",
    "            })\n",
    "\n",
    "        # JSON 저장\n",
    "        with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(job_list, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        print(\"\\n✅ 크롤링 완료 및 JSON 저장 성공\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# 실행\n",
    "input_csv = \"./wanted_merged(1).csv\"\n",
    "output_json = \"./jobs.json\"\n",
    "scrape_jobs_to_json(input_csv, output_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "job311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
